{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 2\n",
    "此部分作业要求使用PCA技术对给定的人脸数据集进行处理\n",
    "本次使用到的人脸数据集是 ORL人脸数据集，共包含40个不同人的400张图像。此数据集下包含40个目录，每个目录下有10张图像，每个目录表示一个不同的人。所有的图像是以PGM格式存储，灰度图，图像大小宽度为92，高度为112。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 用到的包和辅助函数\n",
    "在我的代码中包含两个.py文件，part2和utils，其中part2为主框架代码，utils为用到的部分辅助函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utils所用包\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from Homework1.part1 import linalg\n",
    "from Homework1.part1 import imageManip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# part2所用包\n",
    "from Homework1.part1 import linalg\n",
    "from Homework1.part1 import imageManip\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import utils\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# utils中所有的函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collect_images(root_path):\n",
    "    \"\"\"\n",
    "    批量读入根目录下所有图片\n",
    "    :param root_path: 数据集根目录\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    # 对目录下的文件进行遍历\n",
    "    for file in os.listdir(root_path):\n",
    "        # 对于是文件的情况\n",
    "        if os.path.isfile(os.path.join(root_path, file)):\n",
    "            c = os.path.basename(file)\n",
    "            name = root_path + '\\\\' + c\n",
    "            img = skimage.io.imread(name, as_gray=True)\n",
    "            # 需要对图像进行扁平化处理\n",
    "            flattened_img = img.flatten()\n",
    "            # img = skimage.transform.resize(img, (112, 92))\n",
    "            images.append(flattened_img)\n",
    "        # 对于是文件夹的情况，递归调用\n",
    "        else:\n",
    "            sub_images = collect_images(os.path.join(root_path, file))\n",
    "            images.append(sub_images)\n",
    "    return images\n",
    "\n",
    "\n",
    "def cal_eigenvalues_and_eigenvectors(data_set, dimension):\n",
    "    \"\"\"\n",
    "    计算数据集的特征值和特征向量\n",
    "    :param data_set: 人脸数据集\n",
    "    :param dimension: 维度，即特征值和特征向量个数\n",
    "    :return: 含有dimension个特征值和特征向量的list\n",
    "    \"\"\"\n",
    "    eig = []\n",
    "    for people in range(len(data_set)):\n",
    "        cur_people_images = data_set[people]\n",
    "        cur_people_eig = []\n",
    "        for img in cur_people_images:\n",
    "            # 计算特征值和特征向量, 取前100个\n",
    "            eigenvalues, eigenvectors = linalg.get_eigen_values_and_vectors(img, dimension)\n",
    "            cur_people_eig.append([eigenvalues, eigenvectors])\n",
    "        eig.append(cur_people_eig)\n",
    "    return eig\n",
    "\n",
    "\n",
    "def covert_3d_to_2d(data_set):\n",
    "    \"\"\"\n",
    "    将三维的数据结构转化为2维的\n",
    "    :param data_set: 原始数据集\n",
    "    :return: 转化后的数据集\n",
    "    \"\"\"\n",
    "    people_index, img_num, img_size = data_set.shape\n",
    "    return data_set.reshape(people_index * img_num, img_size)\n",
    "\n",
    "\n",
    "def compare_original_and_reconstructed_image(original_data_set, reconstructed_data_set, img_num, title):\n",
    "    \"\"\"\n",
    "    重建数据集\n",
    "    :param original_data_set: 原始数据集\n",
    "    :param reconstructed_data_set: 重建后的数据集\n",
    "    :param img_num: 需要展示的图片数量\n",
    "    :param title: 图片标题\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(img_num, 2, figsize=(10, 10))\n",
    "    for index in range(img_num):\n",
    "        original_img = original_data_set[index].reshape(112, 92)\n",
    "        reconstructed_img = reconstructed_data_set[index].reshape(112, 92)\n",
    "\n",
    "        # 原始图像\n",
    "        axes[index, 0].imshow(original_img, cmap='gray')\n",
    "        axes[index, 0].set_title(\"Original\")\n",
    "\n",
    "        # 恢复图像\n",
    "        axes[index, 1].imshow(reconstructed_img, cmap='gray')\n",
    "        axes[index, 1].set_title(\"Reconstructed\")\n",
    "        # io.imshow(original_img)\n",
    "        # io.show()\n",
    "        # io.imshow(reconstructed_img)\n",
    "        # io.show()\n",
    "    # 调整子图间距\n",
    "    plt.tight_layout()\n",
    "    # 调整间距\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    # 添加总标题\n",
    "    fig.suptitle(title)\n",
    "    # 显示图像\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 步骤1\n",
    "将数据集划分为80%的训练集，20%的测试集，在训练集上使用PCA将特征维度降为100，即得到100个特征和其对应的特征向量，并使用训练得到的PCA将测试集维度也压缩到100，输出：压缩后的训练集维度和测试集维度、经过PCA得到的特征向量维度。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据集根路径\n",
    "data_path = r'E:\\大三下科目\\计算机视觉\\实验\\实验1\\Homework1\\part2\\data'\n",
    "# 读入数据集\n",
    "images_divided_by_people = utils.collect_images(data_path)\n",
    "# for index in range(len(images_divided_by_people)):\n",
    "#     print(\"current index: {} images num: {}\".format(index, len(images_divided_by_people[index])))\n",
    "# print(len(images_divided_by_people[0]))\n",
    "\n",
    "# 划分训练集和测试集\n",
    "training_rate = 0.8\n",
    "train_set = []\n",
    "test_set = []\n",
    "for people in range(len(images_divided_by_people)):\n",
    "    cur_people_images = images_divided_by_people[people]\n",
    "    train_length = int(len(cur_people_images) * training_rate)\n",
    "    train_set.append(cur_people_images[:train_length])\n",
    "    test_set.append(cur_people_images[train_length:])\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "test_set = np.array(test_set)\n",
    "\n",
    "# 将训练集和测试集进行降维\n",
    "# 因为按照不同的人像进行划分\n",
    "train_people_index, train_img_num, train_img_size = train_set.shape\n",
    "test_people_index, test_img_num, test_img_size = test_set.shape\n",
    "# print(people_index, img_num, img_size)\n",
    "# train_set = train_set.reshape(people_index * img_num, img_size)\n",
    "# print(train_set)\n",
    "train_set = utils.covert_3d_to_2d(train_set)\n",
    "test_set = utils.covert_3d_to_2d(test_set)\n",
    "print(\"train data set dimensions: \", train_set.shape)\n",
    "print(\"test data set dimensions: \", test_set.shape)\n",
    "\n",
    "# 使用PCA降维并输出训练集、测试集维度和得到的特征向量维度\n",
    "pca = PCA(n_components=100)\n",
    "train_set_compressed = pca.fit_transform(train_set)\n",
    "test_set_compressed = pca.transform(test_set)\n",
    "print(\"train set compressed shape: \", train_set_compressed.shape)\n",
    "print(\"test set compressed shape: \", test_set_compressed.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 步骤2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}